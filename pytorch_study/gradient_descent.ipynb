{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 경사하강법\n",
    "\n",
    "- 학습을 위한 예제\n",
    "- H(x) = x\n",
    "- W = 1, b = 0일 때 가장 좋은 값이 된다. \n",
    "- 모델을 학습시켰을 때 좋은지를 판단하는 법을 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[1], [2], [3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function : Intuition\n",
    "\n",
    "- W = 1일 때 cost = 0\n",
    "- 1에서 멀어질수록 cost는 높아진다. \n",
    "- 선형회귀에서 사용하는 Cost Function은 MSE(Mean Squared Error)를 이용한다. \n",
    "- 오차제곱의 평균을 cost로 판단한다. \n",
    "- 그렇다면 어떻게 cost를 최소화시킬 수 있을까?\n",
    "\n",
    "## Gradient Descent : Intuition\n",
    "\n",
    "- **오차제곱**의 평균이라고 했다. 그렇다면 그래프는 2차함수의 형태를 가지게 된다. \n",
    "- 기울기를 이용하면 어떻게 될까?\n",
    "- 기울기의 절대값이 클 수록 cost가 높은 상태이므로, W를 크게 변화시킨다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/100 W : 0.000000, Cost: 4.666667\n",
      "Epoch    1/100 W : 0.466667, Cost: 1.327407\n",
      "Epoch    2/100 W : 0.715556, Cost: 0.377574\n",
      "Epoch    3/100 W : 0.848296, Cost: 0.107399\n",
      "Epoch    4/100 W : 0.919091, Cost: 0.030549\n",
      "Epoch    5/100 W : 0.956849, Cost: 0.008689\n",
      "Epoch    6/100 W : 0.976986, Cost: 0.002472\n",
      "Epoch    7/100 W : 0.987726, Cost: 0.000703\n",
      "Epoch    8/100 W : 0.993454, Cost: 0.000200\n",
      "Epoch    9/100 W : 0.996509, Cost: 0.000057\n",
      "Epoch   10/100 W : 0.998138, Cost: 0.000016\n",
      "Epoch   11/100 W : 0.999007, Cost: 0.000005\n",
      "Epoch   12/100 W : 0.999470, Cost: 0.000001\n",
      "Epoch   13/100 W : 0.999718, Cost: 0.000000\n",
      "Epoch   14/100 W : 0.999849, Cost: 0.000000\n",
      "Epoch   15/100 W : 0.999920, Cost: 0.000000\n",
      "Epoch   16/100 W : 0.999957, Cost: 0.000000\n",
      "Epoch   17/100 W : 0.999977, Cost: 0.000000\n",
      "Epoch   18/100 W : 0.999988, Cost: 0.000000\n",
      "Epoch   19/100 W : 0.999994, Cost: 0.000000\n",
      "Epoch   20/100 W : 0.999997, Cost: 0.000000\n",
      "Epoch   21/100 W : 0.999998, Cost: 0.000000\n",
      "Epoch   22/100 W : 0.999999, Cost: 0.000000\n",
      "Epoch   23/100 W : 0.999999, Cost: 0.000000\n",
      "Epoch   24/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   25/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   26/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   27/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   28/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   29/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   30/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   31/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   32/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   33/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   34/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   35/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   36/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   37/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   38/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   39/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   40/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   41/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   42/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   43/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   44/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   45/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   46/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   47/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   48/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   49/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   50/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   51/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   52/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   53/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   54/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   55/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   56/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   57/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   58/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   59/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   60/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   61/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   62/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   63/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   64/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   65/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   66/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   67/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   68/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   69/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   70/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   71/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   72/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   73/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   74/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   75/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   76/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   77/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   78/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   79/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   80/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   81/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   82/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   83/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   84/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   85/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   86/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   87/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   88/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   89/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   90/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   91/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   92/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   93/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   94/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   95/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   96/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   97/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   98/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch   99/100 W : 1.000000, Cost: 0.000000\n",
      "Epoch  100/100 W : 1.000000, Cost: 0.000000\n",
      "tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "# 경사하강법 구현해보기\n",
    "    \n",
    "W = torch.zeros(1)\n",
    "\n",
    "lr = 0.1\n",
    "\n",
    "nb_epochs = 100\n",
    "\n",
    "for epoch in range(nb_epochs+1):\n",
    "    hypothesis = x_train * W\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "    gradient = torch.mean((hypothesis - y_train) * x_train)\n",
    "    print('Epoch {:4d}/{} W : {:3f}, Cost: {:6f}'.format(epoch, nb_epochs, W.item(), cost.item()))\n",
    "    \n",
    "    W -= lr * gradient\n",
    "\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent by torch.optim\n",
    "\n",
    "- optimizer를 이용해 모델 학습 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/10 W : 1.400000, Cost: 4.666667\n",
      "Epoch    1/10 W : 0.840000, Cost: 0.746667\n",
      "Epoch    2/10 W : 1.064000, Cost: 0.119467\n",
      "Epoch    3/10 W : 0.974400, Cost: 0.019115\n",
      "Epoch    4/10 W : 1.010240, Cost: 0.003058\n",
      "Epoch    5/10 W : 0.995904, Cost: 0.000489\n",
      "Epoch    6/10 W : 1.001638, Cost: 0.000078\n",
      "Epoch    7/10 W : 0.999345, Cost: 0.000013\n",
      "Epoch    8/10 W : 1.000262, Cost: 0.000002\n",
      "Epoch    9/10 W : 0.999895, Cost: 0.000000\n",
      "Epoch   10/10 W : 1.000042, Cost: 0.000000\n"
     ]
    }
   ],
   "source": [
    "W = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "optimizer = torch.optim.SGD([W], lr=0.15)\n",
    "\n",
    "nb_epochs = 10\n",
    "\n",
    "for epoch in range(nb_epochs+1):\n",
    "    hypothesis = x_train * W\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "            \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    print('Epoch {:4d}/{} W : {:3f}, Cost: {:6f}'.format(epoch, nb_epochs, W.item(), cost.item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
