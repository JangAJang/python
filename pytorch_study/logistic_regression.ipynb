{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8df3350b",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "- H(x) = 1 / (1 + e^( (-W)^T * X ) )\n",
    "- cost(W) = -1 / m ∑ ( ylog(H(x)) + (1 - y)log(1 - H(x)) )\n",
    "\n",
    "logistic regression은 dynamic classification 문제이다. \n",
    "- 확률 기반으로 여러 데이터를 0, 1로 분류한다. \n",
    "- 즉, P(y = 1 | X) 같은 확률을 예측하고 임계값을 기준으로 0, 1을 분류하는 방식이다. \n",
    "- dynamic classification이란, 정확히 0/1이 아닌 값들에 대한 분류이다. X가 바뀔 때 마다 동적으로 결과가 바뀔 수 있으며, 가중치에 따라 입력을 받아 분류함\n",
    "\n",
    "m개의 샘플 데이터가 d의 차원으로 존재할 때 m개의 0, 1로 만들어준다. \n",
    "\n",
    "경사하강법을 통한 가중치 변화값\n",
    "```\n",
    "w := w - a * d(cost(w)) / d(w) (a = learning rate)\n",
    "```\n",
    "가중치 - 학습률 * cost함수 미분값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "367dfe85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2803b32f090>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a7b24b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
    "y_data = [[0], [0], [0], [1], [1], [1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c885bd4",
   "metadata": {},
   "source": [
    "|x_data| = (6, 2)\n",
    "|y_data| = (6, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2f517b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor(x_data)\n",
    "y_train = torch.FloatTensor(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f62d7c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 2])\n",
      "torch.Size([6, 1])\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e334d9e",
   "metadata": {},
   "source": [
    "## Computing Hypothesis\n",
    "\n",
    "위의 H(x)를 코드로 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "269e9dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e^1 equals:  tensor([2.7183])\n"
     ]
    }
   ],
   "source": [
    "print('e^1 equals: ', torch.exp(torch.FloatTensor([1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "99b27f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.zeros((2, 1), requires_grad = True)\n",
    "b = torch.zeros(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1c6bfce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis_by_manual = 1 / (1 + torch.exp(-(x_train.matmul(W) + b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "102b27a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], grad_fn=<MulBackward0>)\n",
      "torch.Size([6, 1])\n"
     ]
    }
   ],
   "source": [
    "print(hypothesis_by_manual)\n",
    "print(hypothesis_by_manual.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a061c87",
   "metadata": {},
   "source": [
    "사실 이렇게 할 필요 없이 torch.sigmoid를 이용하면 된다. \n",
    "sigmoid함수란 sig(x) = 1 / (1 + e ^ (-x))로, x대신에 우리가 윈하는 값을 넣어주면 된다. \n",
    "\n",
    "결국 아래의 식이 성립하게 된다. \n",
    "\n",
    "```\n",
    "1 / (1 + torch.exp(-(x_train.matmul(W) + b))) == torch.sigmoid(x_train.matmul(W) + b)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2d626c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], grad_fn=<SigmoidBackward0>)\n",
      "torch.Size([6, 1])\n"
     ]
    }
   ],
   "source": [
    "hypothesis = torch.sigmoid(x_train.matmul(W) + b)\n",
    "print(hypothesis)\n",
    "print(hypothesis.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8051547b",
   "metadata": {},
   "source": [
    "## Cost Function\n",
    "\n",
    "위에 작성한 cost(W) = -1 / m ∑ ( ylog(H(x)) + (1 - y)log(1 - H(x)) ) 라는 식을 직접 구현하는 과정이다. \n",
    "여기에서 H(x)란, p(x=1; w)로, w가 주어졌을 때 x가 1일 확률이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "12aa7d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "print(hypothesis)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2c3bb20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6931],\n",
      "        [0.6931],\n",
      "        [0.6931],\n",
      "        [0.6931],\n",
      "        [0.6931],\n",
      "        [0.6931]], grad_fn=<NegBackward0>)\n",
      "tensor(0.6931, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "losses = -(y_train * torch.log(hypothesis) + (1-y_train) * torch.log(1 - hypothesis))\n",
    "print(losses)\n",
    "\n",
    "cost = losses.mean()\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eab9bd0",
   "metadata": {},
   "source": [
    "이렇게 하지 말고 torch.nn.functional에 존재하는 binary_cross_entrophy를 이용하면 편하다. \n",
    "이걸 줄여서 bce라고 하기도 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7ed31649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.binary_cross_entropy(hypothesis, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc97019",
   "metadata": {},
   "source": [
    "## Whole Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a16ffc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost:  0.693147\n",
      "Epoch  100/1000 Cost:  0.134722\n",
      "Epoch  200/1000 Cost:  0.0806431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  300/1000 Cost:  0.0579\n",
      "Epoch  400/1000 Cost:  0.0452997\n",
      "Epoch  500/1000 Cost:  0.037261\n",
      "Epoch  600/1000 Cost:  0.0316725\n",
      "Epoch  700/1000 Cost:  0.0275559\n",
      "Epoch  800/1000 Cost:  0.0243943\n",
      "Epoch  900/1000 Cost:  0.0218883\n",
      "Epoch 1000/1000 Cost:  0.0198522\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD([W, b], lr=1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "\n",
    "for epoch in range(nb_epochs+1):\n",
    "    hypothesis = torch.sigmoid(x_train.matmul(W) + b)\n",
    "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0 :\n",
    "        print('Epoch {:4d}/{} Cost: {: .6}'.format(epoch, nb_epochs, cost.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94911b79",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9e2662be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "prediction = hypothesis >= torch.FloatTensor([0.5])\n",
    "print(prediction[:5].type(torch.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9e577e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [ True],\n",
      "        [ True]])\n",
      "tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1]], dtype=torch.uint8)\n",
      "tensor([[True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True]])\n"
     ]
    }
   ],
   "source": [
    "print(prediction[:5])\n",
    "print(y_train[:5].type(torch.uint8))\n",
    "\n",
    "correct_prediction = prediction.float() == y_train\n",
    "print(correct_prediction[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfb562d",
   "metadata": {},
   "source": [
    "이렇게 사용하기 보단, 클래스를 이용해 처리하는게 낫다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "42703394",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(2, 1) \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.linear(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "072619ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BinaryClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fdb9a5",
   "metadata": {},
   "source": [
    "위의 클래스를 보았을 때, Linear를 이용해 W, b 파라미터를 추가한다. \n",
    "이를 통해 로지스틱스 회귀에서, 샘플 데이터의 개수는 모르지만 2차원이라는 것을 알 수 있다. \n",
    "\n",
    "즉, W = (2, 1), b = (1)이라는 것을 알 수 있다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f58e930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/100 Cost: 0.539713 Accuracy 83.33\n",
      "Epoch   10/100 Cost: 0.614853 Accuracy 66.67\n",
      "Epoch   20/100 Cost: 0.441875 Accuracy 66.67\n",
      "Epoch   30/100 Cost: 0.373145 Accuracy 83.33\n",
      "Epoch   40/100 Cost: 0.316358 Accuracy 83.33\n",
      "Epoch   50/100 Cost: 0.266094 Accuracy 83.33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   60/100 Cost: 0.220498 Accuracy 100.00\n",
      "Epoch   70/100 Cost: 0.182095 Accuracy 100.00\n",
      "Epoch   80/100 Cost: 0.157299 Accuracy 100.00\n",
      "Epoch   90/100 Cost: 0.144091 Accuracy 100.00\n",
      "Epoch  100/100 Cost: 0.134272 Accuracy 100.00\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "nb_epochs = 100\n",
    "\n",
    "for epoch in range(nb_epochs+1):\n",
    "    hypothesis = model(x_train)\n",
    "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        prediction = hypothesis >= torch.FloatTensor([0.5])\n",
    "        correct_prediction = prediction.float() == y_train\n",
    "        accuracy = correct_prediction.sum().item() / len(correct_prediction)\n",
    "        \n",
    "        print('Epoch {:4d}/{} Cost: {:6f} Accuracy {:2.2f}%'.format(epoch, nb_epochs, cost.item(), accuracy * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
